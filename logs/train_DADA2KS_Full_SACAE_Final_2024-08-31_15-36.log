Logging output to ./logs/DADA2KS_Full_SACAE_Final/train_DADA2KS_Full_SACAE_Final_2024-08-31_15-36.log
# train set: 82, eval set: 82
Epoch: 1 / 50:   0%|          | 0/16 [00:00<?, ?it/s]Epoch: 1 / 50:   6%|▋         | 1/16 [03:50<57:37, 230.50s/it]Epoch: 1 / 50:  12%|█▎        | 2/16 [07:35<53:22, 228.77s/it]Epoch: 1 / 50:  19%|█▉        | 3/16 [11:25<49:38, 229.10s/it]Epoch: 1 / 50:  25%|██▌       | 4/16 [15:09<45:30, 227.56s/it]Epoch: 1 / 50:  31%|███▏      | 5/16 [18:52<41:28, 226.26s/it]Epoch: 1 / 50:  38%|███▊      | 6/16 [22:38<37:41, 226.17s/it]Epoch: 1 / 50:  38%|███▊      | 6/16 [24:50<41:24, 248.44s/it]
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([5, 128])
torch.Size([64, 640])
torch.Size([64, 640])
Traceback (most recent call last):
  File "main_sac.py", line 346, in <module>
    train()
  File "main_sac.py", line 213, in train
    updates = train_per_epoch(traindata_loader, env, agent, cfg, writer, e, memory, updates)
  File "main_sac.py", line 129, in train_per_epoch
    outputs = agent.update_parameters(memory, updates)
  File "/home/achini/Documents/DRIVE-master/RLlib/SAC/sac.py", line 261, in update_parameters
    self.update_critic(state_batch, action_batch, reward_batch, next_state_batch, mask_batch, rnn_state_batch)
  File "/home/achini/Documents/DRIVE-master/RLlib/SAC/sac.py", line 138, in update_critic
    next_acc_state_action, _, next_acc_state_log_pi, _ = self.policy_accident.sample(next_acc_state, rnn_state_batch)
  File "/home/achini/Documents/DRIVE-master/RLlib/SAC/agents.py", line 179, in sample
    mean, log_std, rnn_state = self.forward(state, rnn_state, detach=detach)
  File "/home/achini/Documents/DRIVE-master/RLlib/SAC/agents.py", line 159, in forward
    x = self.state_encoder(state, detach=detach)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/achini/Documents/DRIVE-master/RLlib/SAC/agents.py", line 53, in forward
    h = self.encoder(state)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/achini/miniconda3/envs/pyRL/lib/python3.7/site-packages/torch/nn/functional.py", line 1370, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: size mismatch, m1: [64 x 640], m2: [128 x 64] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136
Done!
